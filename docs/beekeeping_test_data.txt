--- Page 3 ---
Query + LLM
Entity Name:  Beekeeper
Entity Type: PERSON
Description: A Beekeeper is
an individual who produces ...
Original Chunks ID: xxx
Source: Honey Bee
Target: Industrial agriculture
Keywords: Agriculture ...
Description:Honey Bees are
negatively impacted ...
Original Chunks ID: xxx
... BEEKEEPER‘spractices involve
the methods and strategies employed
by beekeepers to manage bee
colonies and ensure their health and
productivity. A Beekeeper is an
individual who produces honey and
other related products, playing a
crucial role in ……
Beekeepers engage in various tasks,
including observing bee behavior,
monitoring hive conditions,
preventing pest infestations, and
utilizing techniques to handle bees,
such as using smoke to calm them ...
 Original Text
-----Entities-----
"Beekeeper",”A Beekeeper is an
individual who produces honey and
other related products, playing a
crucial role in ......”
-Relationships-
"Beekeeper",“bee","Beekeepers
manage bees but do not develop
individual relationships with them
due to the limited interaction time
with each hive.”
----Contexts----
BEEKEEPER's practices involve the
methods and strategies employed
by beekeepers to manage ……
Graph-based Text Indexing Dual-level Retrieval Paradigm
Entity & Rel Extraction
Beekeeper BeesObserve
Beekeeper
A beekeeper
is an person
who…
LLM Profiling
Beekeeper beekeeper
Deduplication
…
Match
Index Graph
used for Retrieval
Beekeeper Honey Bee
…Formers Hive
Low-level Keys
Agriculture Production
Environmental Impact …
High-level Keys
Entities
Relations
Retrieved Content
Figure 1: Overall architecture of the proposed LightRAG framework.
includes two key functionalities: i) Data Indexer φ(·): which involves building a specific data
structure ˆD based on the external database D. ii) Data Retriever ψ(·): The relevant documents are
obtained by comparing the query against the indexed data, also denoted as “relevant documents”. By
leveraging the information retrieved through ψ(·) along with the initial query q, the generative model
G(·) efficiently produces high-quality, contextually relevant responses.
In this work, we target several key points essential for an efficient and effective Retrieval-Augmented
Generation (RAG) system which are elaborated below:
• Comprehensive Information Retrieval: The indexing function φ(·) must be adept at extracting
global information, as this is crucial for enhancing the model’s ability to answer queries effectively.
• Efficient and Low-Cost Retrieval : The indexed data structure ˆD must enable rapid and cost-
efficient retrieval to effectively handle a high volume of queries.
• Fast Adaptation to Data Changes: The ability to swiftly and efficiently adjust the data structure
to incorporate new information from the external knowledge base, is crucial for ensuring that the
system remains current and relevant in an ever-changing information landscape.
3 T HE LIGHT RAG A RCHITECTURE
3.1 G RAPH -BASED TEXT INDEXING
Graph-Enhanced Entity and Relationship Extraction . Our LightRAG enhances the retrieval
system by segmenting documents into smaller, more manageable pieces. This strategy allows for
quick identification and access to relevant information without analyzing entire documents. Next,
we leverage LLMs to identify and extract various entities (e.g., names, dates, locations, and events)
along with the relationships between them. The information collected through this process will be
used to create a comprehensive knowledge graph that highlights the connections and insights across
the entire collection of documents. We formally represent this graph generation module as follows:
ˆD = (ˆV, ˆE) =Dedupe ◦ Prof(V, E), V, E = ∪Di∈DRecog(Di) (2)
where ˆD represents the resulting knowledge graphs. To generate this data, we apply three main
processing steps to the raw text documents Di. These steps utilize a LLM for text analysis and
processing. Details about the prompt templates and specific settings for this part can be found in
Appendix 7.3.2. The functions used in our graph-based text indexing paradigm are described as:
• Extracting Entities and Relationships. R(·): This function prompts a LLM to identify entities
(nodes) and their relationships (edges) within the text data. For instance, it can extract entities
like "Cardiologists" and "Heart Disease," and relationships such as "Cardiologists diagnose Heart
Disease" from the text: "Cardiologists assess symptoms to identify potential heart issues." To
improve efficiency, the raw textD is segmented into multiple chunks Di.
• LLM Profiling for Key-Value Pair Generation. P(·): We employ a LLM-empowered profiling
function, P(·), to generate a text key-value pair (K, V) for each entity node in V and relation
edge in E. Each index key is a word or short phrase that enables efficient retrieval, while the
corresponding value is a text paragraph summarizing relevant snippets from external data to aid in
text generation. Entities use their names as the sole index key, whereas relations may have multiple
index keys derived from LLM enhancements that include global themes from connected entities.
• Deduplication to Optimize Graph Operations . D(·): Finally, we implement a deduplication
function, D(·), that identifies and merges identical entities and relations from different segments of
3
--- Page 5 ---
• (iii) Incorporating High-Order Relatedness. To enhance the query with higher-order relatedness,
LightRAGfurther gathers neighboring nodes within the local subgraphs of the retrieved graph
elements. This process involves the set {vi|vi ∈ V ∧(vi ∈ Nv ∨ vi ∈ Ne)}, where Nv and Ne
represent the one-hop neighboring nodes of the retrieved nodes v and edges e, respectively.
This dual-level retrieval paradigm not only facilitates efficient retrieval of related entities and relations
through keyword matching, but also enhances the comprehensiveness of results by integrating relevant
structural information from the constructed knowledge graph.
3.3 R ETRIEVAL -AUGMENTED ANSWER GENERATION
Utilization of Retrieved Information. Utilizing the retrieved information ψ(q; ˆD), our LightRAG
employs a general-purpose LLM to generate answers based on the collected data. This data comprises
concatenated values V from relevant entities and relations, produced by the profiling function P(·). It
includes names, descriptions of entities and relations, and excerpts from the original text.
Context Integration and Answer Generation. By unifying the query with this multi-source text,
the LLM generates informative answers tailored to the user’s needs, ensuring alignment with the
query’s intent. This approach streamlines the answer generation process by integrating both context
and query into the LLM model, as illustrated in detailed examples (Appendix 7.2).
3.4 C OMPLEXITY ANALYSIS OF THE LIGHT RAG F RAMEWORK
In this section, we analyze the complexity of our proposed LightRAG framework, which can be
divided into two main parts. The first part is the graph-based Index phase. During this phase, we use
the large language model (LLM) to extract entities and relationships from each chunk of text. As
a result, the LLM needs to be called total tokens
chunk size times. Importantly, there is no additional overhead
involved in this process, making our approach highly efficient in managing updates to new text.
The second part of the process involves the graph-based retrieval phase. For each query, we first
utilize the large language model (LLM) to generate relevant keywords. Similar to current Retrieval-
Augmented Generation (RAG) systems Gao et al. (2023; 2022); Chan et al. (2024), our retrieval
mechanism relies on vector-based search. However, instead of retrieving chunks as in conventional
RAG, we concentrate on retrieving entities and relationships. This approach markedly reduces
retrieval overhead compared to the community-based traversal method used in GraphRAG.
4 E VALUATION
We conduct empirical evaluations on benchmark data to assess the effectiveness of the proposed
LightRAG framework by addressing the following research questions:• (RQ1): How does LightRAG
compare to existing RAG baseline methods in terms of generation performance? • (RQ2): How do
dual-level retrieval and graph-based indexing enhance the generation quality of LightRAG? • (RQ3):
What specific advantages does LightRAG demonstrate through case examples in various scenarios? •
(RQ4): What are the costs associated with LightRAG, as well as its adaptability to data changes?
4.1 E XPERIMENTAL SETTINGS
Evaluation Datasets. To conduct a comprehensive analysis of LightRAG, we selected four datasets
from the UltraDomain benchmark (Qian et al., 2024). The UltraDomain data is sourced from 428
college textbooks and encompasses 18 distinct domains, including agriculture, social sciences, and
humanities. From these, we chose the Agriculture, CS, Legal, and Mix datasets. Each dataset contains
between 600,000 and 5,000,000 tokens, with detailed information provided in Table 4. Below is a
specific introduction to the four domains utilized in our experiments:
• Agriculture: This domain focuses on agricultural practices, covering a range of topics including
beekeeping, hive management, crop production, and disease prevention.
• CS: This domain focuses on computer science and encompasses key areas of data science and
software engineering. It particularly highlights machine learning and big data processing, featuring
content on recommendation systems, classification algorithms, and real-time analytics using Spark.
5
